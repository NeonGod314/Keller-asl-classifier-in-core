{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### @author : Jimmy Fails\n",
    "\n",
    "## Training and testing for Android_ASL application\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shubhamkumar.singh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading the data for training\n",
      "\n",
      "classes extracted from the folder \n",
      " ['A', 'B', 'C']\n",
      "Data loaded\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "# loading data for training\n",
    "print(\"loading the data for training\\n\")\n",
    "class_dir = glob.glob('asl-alphabet/asl_alphabet_train/*')\n",
    "classes   = []\n",
    "for i in class_dir:\n",
    "    classes.append(i.split(\"\\\\\")[1])\n",
    "print(\"classes extracted from the folder \\n\", classes)    \n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for clas in class_dir:\n",
    "    \n",
    "    img_loc=glob.glob(str(clas)+str(\"/*\"))\n",
    "    class_name=clas.split(\"\\\\\")[1]\n",
    "    \n",
    "    for image in img_loc:\n",
    "        img         = np.array(mpimg.imread(image))\n",
    "        img_flatten = img.reshape(120000,1)\n",
    "        img_std     = img_flatten/255.\n",
    "        \n",
    "        x_train.append(img_std)\n",
    "        y_train.append(class_name)\n",
    "print(\"Data loaded\")\n",
    "print(\"-----------------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading the data for test\n",
      "\n",
      "test data loaded\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "# loading the data for test\n",
    "print(\"loading the data for test\\n\")\n",
    "test_data_dir = glob.glob('asl-alphabet/later/asl_alphabet_test/*')\n",
    "test_classes   = []   \n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for image in test_data_dir:\n",
    "        img         = np.array(mpimg.imread(image))\n",
    "        img_flatten = img.reshape(120000,1)\n",
    "        img_std     = img_flatten/255.\n",
    "        \n",
    "        x_test.append(img_std)\n",
    "        y_test.append((image.split(\"\\\\\")[1]).split(\"_\")[0])    \n",
    "print(\"test data loaded\")\n",
    "print(\"-----------------------------\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input training data (ip_nodes, ip_imgs) : (9000, 120000)\n",
      "Shape of input test data (ip_nodes, ip_imgs) : (3, 120000)\n"
     ]
    }
   ],
   "source": [
    "# processing data into the suitable format\n",
    "x_train = np.array(x_train)\n",
    "x_train = np.squeeze(x_train)\n",
    "x_train = x_train.T\n",
    "x_test  = np.array(x_test)\n",
    "x_test  = np.squeeze(x_test)\n",
    "x_test  = x_test.T\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_train = y_train.reshape(1,9000)\n",
    "y_test  = np.array(y_test)\n",
    "y_test  = y_test.reshape(1,3)\n",
    "\n",
    "print(\"Shape of input training data (ip_nodes, ip_imgs) :\",x_train.shape)\n",
    "print(\"Shape of input test data (ip_nodes, ip_imgs) :\",x_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = Tensor(\"X:0\", shape=(120000, ?), dtype=float32)\n",
      "Y = Tensor(\"Y:0\", shape=(3, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def create_placeholders(n_x,n_y):\n",
    "    X=tf.placeholder(tf.float32,[n_x,None], name=\"X\")\n",
    "    Y=tf.placeholder(tf.float32,[n_y,None], name=\"Y\")\n",
    "    return X, Y\n",
    "X, Y= create_placeholders(120000,3)\n",
    "print(\"X = \" + str(X))\n",
    "print(\"Y = \" + str(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "    tf.set_random_seed(1)\n",
    "    \n",
    "    W1 = tf.get_variable(\"W1\", [25,120000], initializer=tf.contrib.layers.xavier_initializer(seed=1)) \n",
    "    b1 = tf.get_variable(\"b1\", [25,1],initializer=tf.zeros_initializer())\n",
    "    W2 = tf.get_variable(\"W2\", [12,25], initializer=tf.contrib.layers.xavier_initializer(seed=1))\n",
    "    b2 = tf.get_variable(\"b2\", [12,1],initializer=tf.zeros_initializer())\n",
    "    W3 = tf.get_variable(\"W3\", [3,12], initializer=tf.contrib.layers.xavier_initializer(seed=1))\n",
    "    b3 = tf.get_variable(\"b3\", [3,1],initializer=tf.zeros_initializer())\n",
    "    \n",
    "    parameters={\"W1\":W1,\n",
    "                \"b1\":b1,\n",
    "                \"W2\":W2,\n",
    "                \"b2\":b2,\n",
    "                \"W3\":W3,\n",
    "                \"b3\":b3}\n",
    "    \n",
    "    return parameters\n",
    "\n",
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    parameters = initialize_parameters()\n",
    "    print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "    print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "    print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "    print(\"b2 = \" + str(parameters[\"b2\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z3 = Tensor(\"Add_2:0\", shape=(3, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    W3 = parameters[\"W3\"]\n",
    "    b3 = parameters[\"b3\"]\n",
    "    \n",
    "    Z1 = tf.add(tf.matmul(W1, X), b1)\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2,A1), b2)\n",
    "    A2 = tf.nn.relu(Z2)\n",
    "    Z3 = tf.add(tf.matmul(W3,A2), b3)\n",
    "    \n",
    "    return Z3\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    X, Y = create_placeholders(120000, 3)\n",
    "    parameters = initialize_parameters()\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    print(\"Z3 = \" + str(Z3))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-44-51b6d9f3b1aa>:5: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "cost = Tensor(\"Mean:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# computing cost or the loss function\n",
    "def compute_cost(Z3, Y):\n",
    "    logits = tf.transpose(Z3)\n",
    "    labels = tf.transpose(Y)\n",
    "    cost   = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "    \n",
    "    return cost\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    X, Y = create_placeholders(120000, 3)\n",
    "    parameters = initialize_parameters()\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    print(\"cost = \" + str(cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the model\n",
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001, num_epochs=1500, minibatch_size=32, print_cost=True):\n",
    "    ops.reset_default_graph()\n",
    "    tf.set_random_seed(1)\n",
    "    seed=3\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
